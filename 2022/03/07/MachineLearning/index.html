<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="简单记录一些笔记"><title>机器学习基础 | Disda</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 6.0.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习基础</h1><a id="logo" href="/.">Disda</a><p class="description">Disda’s Blog</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-4-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习基础</h1><div class="post-content"><span id="more"></span>

<!-- toc -->

<ul>
<li><a href="#%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93">算法总结</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">数据预处理</a></li>
<li><a href="#%E5%88%86%E7%B1%BB">分类</a><ul>
<li><a href="#%E5%9B%9E%E5%BD%92%E6%A0%91">回归树</a></li>
<li><a href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97">随机森林</a></li>
<li><a href="#%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E6%A3%AE%E6%9E%97">梯度提升森林</a></li>
<li><a href="#svc%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E9%9C%80%E8%A6%81%E6%A0%87%E5%87%86%E5%8C%96-%E6%89%BE%E5%B0%91%E6%95%B0%E7%B1%BB%E7%9B%B8%E5%AF%B9%E6%93%85%E9%95%BF">SVC(支持向量机需要标准化) 找少数类相对擅长</a></li>
<li><a href="#%E5%88%86%E7%B1%BBonekey">分类OneKey</a></li>
<li><a href="#%E5%88%86%E7%B1%BB%E8%B0%83%E5%8F%82onekey">分类调参Onekey</a></li>
</ul>
</li>
<li><a href="#%E6%A8%A1%E6%9D%BF">模板</a><ul>
<li><a href="#%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B">泰坦尼克</a></li>
<li><a href="#%E8%B0%83%E4%BC%98">调优</a></li>
<li><a href="#ridge">Ridge</a></li>
<li><a href="#lasso">Lasso</a></li>
<li><a href="#%E5%A4%9A%E6%AD%A5%E9%95%BF%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97">多步长时间序列</a></li>
</ul>
</li>
<li><a href="#%E8%B8%A9%E5%9D%91">踩坑</a></li>
<li><a href="#trick">Trick</a></li>
</ul>
<!-- tocstop -->

<h2><span id="算法总结">算法总结</span></h2><table>
<thead>
<tr>
<th>分类</th>
<th>回归</th>
</tr>
</thead>
<tbody><tr>
<td>分类树<strong>tree.DecisionTreeClassififier</strong></td>
<td>回归树<strong>tree.DecisionTreeRegressor</strong></td>
</tr>
<tr>
<td>随机森林<strong>ensemble.RandomForestClassifier</strong></td>
<td>回归森林<strong>ensemble.RandomForestRegressor</strong></td>
</tr>
<tr>
<td>逻辑回归<strong>linear_model.LogisticRegression</strong></td>
<td></td>
</tr>
<tr>
<td>KNN <strong>neighbors .KNeighborsClassifier</strong></td>
<td></td>
</tr>
<tr>
<td>Naive Bayes</td>
<td></td>
</tr>
<tr>
<td>梯度提升树<strong>ensemble.GradientBoostingRegressor</strong></td>
<td></td>
</tr>
<tr>
<td>SVC <strong>svm.SVC</strong></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=<span class="number">0.3</span>,random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>不对分类型变量做无量纲化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">col = X.columns.tolist()</span><br><span class="line">cate = X.columns[X.dtypes == <span class="string">&quot;object&quot;</span>].tolist()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> cate:</span><br><span class="line">    col.remove(i)</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss = ss.fit(X.loc[:,col])</span><br><span class="line">X.loc[:,col] = ss.transform(X.loc[:,col])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.describe([<span class="number">0.01</span>,<span class="number">0.05</span>,<span class="number">0.1</span>,<span class="number">0.25</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.9</span>,<span class="number">0.99</span>]).T</span><br></pre></td></tr></table></figure>

<ul>
<li>训练集特征和预测集特征plot一下，看看分布像不像，看看后面需要防止过拟合，交叉验证。</li>
</ul>
<h2><span id="数据预处理">数据预处理</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 观察连续变量，distplot</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.distplot(dataset_raw[<span class="string">&#x27;fnlwgt&#x27;</span>])</span><br></pre></td></tr></table></figure>



<h2><span id="分类">分类</span></h2><h3><span id="回归树">回归树</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化一个分类器</span></span><br><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">clf = clf.fit(Xtrain, Ytrain)</span><br><span class="line"><span class="comment"># 评价结果</span></span><br><span class="line">score = clf.score(Xtest, Ytest)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习曲线</span></span><br><span class="line">n = np.linspace(<span class="number">5</span>,<span class="number">16</span>,<span class="number">10</span>) </span><br><span class="line">score=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> n:</span><br><span class="line">    clf = DecisionTreeClassifier(max_depth=i)</span><br><span class="line">    score.append(cross_val_score(clf,X,y,cv=<span class="number">10</span>).mean())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(score), <span class="built_in">int</span>(n[score.index(<span class="built_in">max</span>(score))]))</span><br><span class="line">plt.plot(n,score)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 网格搜索</span></span><br><span class="line">gini_thresholds = np.linspace(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">20</span>)</span><br><span class="line">parameters = &#123;</span><br><span class="line">    <span class="string">&quot;criterion&quot;</span>:(<span class="string">&#x27;gini&#x27;</span>,<span class="string">&#x27;entropy&#x27;</span>)</span><br><span class="line">    ,<span class="string">&quot;splitter&quot;</span>:(<span class="string">&#x27;best&#x27;</span>,<span class="string">&#x27;random&#x27;</span>)</span><br><span class="line">    ,<span class="string">&#x27;max_depth&#x27;</span>:[*<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>)]</span><br><span class="line">    ,<span class="string">&#x27;min_samples_leaf&#x27;</span>:[*<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">50</span>,<span class="number">5</span>)]</span><br><span class="line">    ,<span class="string">&#x27;min_impurity_decrease&#x27;</span>:[*gini_thresholds]</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">clf = DecisionTreeClassifier(random_state=<span class="number">25</span>)</span><br><span class="line">GS = GridSearchCV(clf,parameters,cv=<span class="number">10</span>)</span><br><span class="line">GS.fit(Xtrain,Ytrain)</span><br></pre></td></tr></table></figure>

<h3><span id="随机森林">随机森林</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 填补缺失</span></span><br><span class="line">X_missing_reg = X_missing.copy()</span><br><span class="line">sortindex = np.argsort(X_missing_reg.isnull().<span class="built_in">sum</span>(axis=<span class="number">0</span>)).values</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> sortindex:</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#构建我们的新特征矩阵和新标签</span></span><br><span class="line">    df = X_missing_reg</span><br><span class="line">    fillc = df.iloc[:,i]</span><br><span class="line">    df = pd.concat([df.iloc[:,df.columns != i],pd.DataFrame(y_full)],axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#在新特征矩阵中，对含有缺失值的列，进行0的填补</span></span><br><span class="line">    df_0 =SimpleImputer(missing_values=np.nan,</span><br><span class="line">                        strategy=<span class="string">&#x27;constant&#x27;</span>,fill_value=<span class="number">0</span>).fit_transform(df)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#找出我们的训练集和测试集</span></span><br><span class="line">    Ytrain = fillc[fillc.notnull()]</span><br><span class="line">    Ytest = fillc[fillc.isnull()]</span><br><span class="line">    Xtrain = df_0[Ytrain.index,:]</span><br><span class="line">    Xtest = df_0[Ytest.index,:]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#用随机森林回归来填补缺失值</span></span><br><span class="line">    rfc = RandomForestRegressor(n_estimators=<span class="number">100</span>)</span><br><span class="line">    rfc = rfc.fit(Xtrain, Ytrain)</span><br><span class="line">    Ypredict = rfc.predict(Xtest)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#将填补好的特征返回到我们的原始的特征矩阵中</span></span><br><span class="line">    X_missing_reg.loc[X_missing_reg.iloc[:,i].isnull(),X_missing_reg.columns[i]] = Ypredict</span><br></pre></td></tr></table></figure>



<h3><span id="梯度提升森林">梯度提升森林</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">gbc = GradientBoostingClassifier().fit(Xtrain,Ytrain)</span><br><span class="line">gbc.score(Xtest,Ytest)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习曲线</span></span><br><span class="line">%%time</span><br><span class="line">n = np.linspace(<span class="number">329</span>,<span class="number">339</span>,<span class="number">10</span>) </span><br><span class="line">score=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> n:</span><br><span class="line">    gbc = GradientBoostingClassifier(n_estimators=<span class="built_in">int</span>(i)).fit(Xtrain,Ytrain)</span><br><span class="line">    score.append(gbc.score(Xtest,Ytest))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(score), <span class="built_in">int</span>(n[score.index(<span class="built_in">max</span>(score))]))</span><br><span class="line">plt.plot(n,score)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3><span id="svc支持向量机需要标准化-找少数类相对擅长">SVC(支持向量机需要标准化) 找少数类相对擅长</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">X = StandardScaler().fit_transform(X)<span class="comment">#将数据转化为0,1正态分布</span></span><br><span class="line"></span><br><span class="line">Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">420</span>)</span><br><span class="line"> </span><br><span class="line">Kernel = [<span class="string">&quot;linear&quot;</span>,<span class="string">&quot;poly&quot;</span>,<span class="string">&quot;rbf&quot;</span>,<span class="string">&quot;sigmoid&quot;</span>]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> kernel <span class="keyword">in</span> Kernel:</span><br><span class="line">    clf= SVC(kernel = kernel</span><br><span class="line">             , gamma=<span class="string">&quot;auto&quot;</span></span><br><span class="line">             , degree = <span class="number">1</span></span><br><span class="line">             , cache_size=<span class="number">5000</span></span><br><span class="line">            ).fit(Xtrain,Ytrain)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;The accuracy under kernel %s is %f&quot;</span> % (kernel,clf.score(Xtest,Ytest)))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 调试rbf</span></span><br><span class="line">score = []</span><br><span class="line">gamma_range = np.logspace(-<span class="number">10</span>, <span class="number">1</span>, <span class="number">50</span>) <span class="comment">#返回在对数刻度上均匀间隔的数字</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> gamma_range:</span><br><span class="line">    clf = SVC(kernel=<span class="string">&quot;rbf&quot;</span>,gamma = i,cache_size=<span class="number">5000</span>).fit(Xtrain,Ytrain)</span><br><span class="line">    score.append(clf.score(Xtest,Ytest))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(score), gamma_range[score.index(<span class="built_in">max</span>(score))])</span><br><span class="line">plt.plot(gamma_range,score)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网格搜索rbf</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit<span class="comment">#用于支持带交叉验证的网格搜索</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV<span class="comment">#带交叉验证的网格搜索</span></span><br><span class="line"> </span><br><span class="line">time0 = time()</span><br><span class="line"> </span><br><span class="line">gamma_range = np.logspace(-<span class="number">10</span>,<span class="number">1</span>,<span class="number">20</span>)</span><br><span class="line">coef0_range = np.linspace(<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">param_grid = <span class="built_in">dict</span>(gamma = gamma_range</span><br><span class="line">                  ,coef0 = coef0_range)</span><br><span class="line">cv = StratifiedShuffleSplit(n_splits=<span class="number">5</span>, test_size=<span class="number">0.3</span>, random_state=<span class="number">420</span>)<span class="comment">#将数据分为5份，5份数据中测试集占30%</span></span><br><span class="line">grid = GridSearchCV(SVC(kernel = <span class="string">&quot;poly&quot;</span>,degree=<span class="number">1</span>,cache_size=<span class="number">5000</span></span><br><span class="line">                        ,param_grid=param_grid</span><br><span class="line">                        ,cv=cv)</span><br><span class="line">grid.fit(X, y)</span><br><span class="line"> </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The best parameters are %s with a score of %0.5f&quot;</span> % (grid.best_params_, </span><br><span class="line">grid.best_score_))</span><br><span class="line"><span class="built_in">print</span>(time()-time0)</span><br><span class="line"></span><br><span class="line">                    </span><br><span class="line"><span class="comment">#调线性核函数</span></span><br><span class="line">score = []</span><br><span class="line">C_range = np.linspace(<span class="number">0.01</span>,<span class="number">30</span>,<span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> C_range:</span><br><span class="line">    clf = SVC(kernel=<span class="string">&quot;linear&quot;</span>,C=i,cache_size=<span class="number">5000</span>).fit(Xtrain,Ytrain)</span><br><span class="line">    score.append(clf.score(Xtest,Ytest))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(score), C_range[score.index(<span class="built_in">max</span>(score))])</span><br><span class="line">plt.plot(C_range,score)</span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment">#换rbf</span></span><br><span class="line">score = []</span><br><span class="line">C_range = np.linspace(<span class="number">0.01</span>,<span class="number">30</span>,<span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> C_range:</span><br><span class="line">    clf = SVC(kernel=<span class="string">&quot;rbf&quot;</span>,C=i,gamma = <span class="number">0.012742749857031322</span>,cache_size=<span class="number">5000</span>).fit(Xtrain,Ytrain)</span><br><span class="line">    score.append(clf.score(Xtest,Ytest))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(score), C_range[score.index(<span class="built_in">max</span>(score))])</span><br><span class="line">plt.plot(C_range,score)</span><br><span class="line">plt.show()</span><br><span class="line"> </span><br><span class="line"><span class="comment">#进一步细化</span></span><br><span class="line">score = []</span><br><span class="line">C_range = np.linspace(<span class="number">5</span>,<span class="number">7</span>,<span class="number">50</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> C_range:</span><br><span class="line">    clf = SVC(kernel=<span class="string">&quot;rbf&quot;</span>,C=i,gamma = </span><br><span class="line"><span class="number">0.012742749857031322</span>,cache_size=<span class="number">5000</span>).fit(Xtrain,Ytrain)</span><br><span class="line">    score.append(clf.score(Xtest,Ytest))</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">max</span>(score), C_range[score.index(<span class="built_in">max</span>(score))])</span><br><span class="line">plt.plot(C_range,score)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">                    </span><br><span class="line"><span class="comment">#解决样本不均衡  class_weight（一般比较少用，误伤严重）</span></span><br><span class="line"><span class="comment">#设定class_weight</span></span><br><span class="line">wclf = svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, class_weight=&#123;<span class="number">1</span>: <span class="number">10</span>&#125;)</span><br><span class="line">wclf.fit(X, y)</span><br><span class="line"></span><br><span class="line">                    </span><br><span class="line"><span class="comment"># 召回率</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, recall_score</span><br><span class="line">resutl = clf.predict(Xtest)</span><br><span class="line">recall = recall_score(Ytest,result)                    </span><br><span class="line"><span class="comment"># 提高召回率</span></span><br><span class="line">class_weight = &#123;<span class="number">1</span>:<span class="number">10</span>&#125; <span class="comment"># 类别：权重</span></span><br><span class="line"><span class="comment"># 平衡</span></span><br><span class="line">class_weigth =<span class="string">&#x27;balanced&#x27;</span></span><br><span class="line">                    </span><br><span class="line">                    </span><br><span class="line"><span class="comment"># 调参</span></span><br><span class="line">irange = np.linspace(<span class="number">0.01</span>,<span class="number">0.05</span>,<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> irange:</span><br><span class="line">    times = time()</span><br><span class="line">    clf = SVC(kernel = <span class="string">&quot;linear&quot;</span></span><br><span class="line">             ,gamma=<span class="string">&quot;auto&quot;</span></span><br><span class="line">             ,cache_size = <span class="number">5000</span></span><br><span class="line">             ,class_weight = &#123;<span class="number">1</span>:<span class="number">1</span>+i&#125;</span><br><span class="line">             ).fit(Xtrain, Ytrain)</span><br><span class="line">    result = clf.predict(Xtest)</span><br><span class="line">    score = clf.score(Xtest,Ytest)</span><br><span class="line">    recall = recall_score(Ytest, result)</span><br><span class="line">    auc = roc_auc_score(Ytest,clf.decision_function(Xtest))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;under ratio 1:%f testing accuracy %f, recall is %f&#x27;, auc is %f&quot;</span> % (<span class="number">1</span>+i,score,recall,auc))</span><br><span class="line">    <span class="built_in">print</span>(datetime.datetime.fromtimestamp(time()-times).strftime(<span class="string">&quot;%M:%S:%f&quot;</span>))                    </span><br></pre></td></tr></table></figure>

<h3><span id="分类onekey">分类OneKey</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression,RidgeClassifier,SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC,LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_models</span>(<span class="params">models=&#123;&#125;</span>):</span><br><span class="line">    models[<span class="string">&#x27;LogisticRegression&#x27;</span>]=LogisticRegression()</span><br><span class="line">    models[<span class="string">&#x27;RidgeClassifier&#x27;</span>]=RidgeClassifier()</span><br><span class="line">    models[<span class="string">&#x27;SGDClassifier&#x27;</span>]=SGDClassifier()</span><br><span class="line">    models[<span class="string">&#x27;RandomForestClassifier&#x27;</span>]=RandomForestClassifier()</span><br><span class="line">    models[<span class="string">&#x27;GradientBoostingClassifier&#x27;</span>]=GradientBoostingClassifier()</span><br><span class="line">    models[<span class="string">&#x27;AdaBoostClassifier&#x27;</span>]=AdaBoostClassifier()</span><br><span class="line">    models[<span class="string">&#x27;KNN&#x27;</span>] = KNeighborsClassifier()</span><br><span class="line">    models[<span class="string">&#x27;GaussianNB&#x27;</span>] =  GaussianNB()</span><br><span class="line">    models[<span class="string">&#x27;SVC&#x27;</span>]=SVC()</span><br><span class="line">    models[<span class="string">&#x27;LinearSVC&#x27;</span>]=LinearSVC()</span><br><span class="line">    <span class="keyword">return</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_pipe</span>(<span class="params">model</span>):</span><br><span class="line">    s = [(<span class="string">&#x27;MinMaxScaler&#x27;</span>,MinMaxScaler()),(<span class="string">&#x27;model&#x27;</span>,model)]</span><br><span class="line">    <span class="keyword">return</span> Pipeline(steps=s)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pred</span>(<span class="params">model,x</span>):</span><br><span class="line">    <span class="keyword">return</span> model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">model,x,y</span>):</span><br><span class="line">    <span class="keyword">return</span> model.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">valid</span>(<span class="params">model,x,y,cv=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> cross_val_score(model,x,y,cv=cv)</span><br><span class="line"></span><br><span class="line">s=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> n,m <span class="keyword">in</span> get_models().items():</span><br><span class="line">    pipe = make_pipe(m)</span><br><span class="line">    s[n] = valid(pipe,x,y).mean()</span><br><span class="line">    </span><br><span class="line">order = <span class="built_in">sorted</span>(s.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line">order</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot_data = pd.DataFrame(data=order)</span><br><span class="line">plot_data.columns = [<span class="string">&#x27;algo&#x27;</span>,<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">plot_data.set_index(<span class="string">&#x27;algo&#x27;</span>).plot.bar(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">360</span>)</span><br><span class="line"><span class="string">f&#x27;%s is the best,score is %f&#x27;</span>%(order[<span class="number">0</span>][<span class="number">0</span>],order[<span class="number">0</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_pipeline</span>(<span class="params">model,X, Y</span>):</span><br><span class="line">	steps = <span class="built_in">list</span>()</span><br><span class="line">	<span class="comment"># standardization</span></span><br><span class="line">	steps.append((<span class="string">&#x27;standardize&#x27;</span>, StandardScaler()))</span><br><span class="line">	<span class="comment"># normalization</span></span><br><span class="line">	steps.append((<span class="string">&#x27;normalize&#x27;</span>, MinMaxScaler()))</span><br><span class="line">	<span class="comment"># the model</span></span><br><span class="line">	steps.append((<span class="string">&#x27;model&#x27;</span>, model))</span><br><span class="line">	<span class="comment"># create pipeline</span></span><br><span class="line">	pipeline = Pipeline(steps)</span><br><span class="line">	<span class="keyword">return</span> cross_val_score(pipeline,X,Y,cv=<span class="number">4</span>).mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dic = &#123;&#125;</span><br><span class="line">models = get_models()</span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    dic[name] = make_pipeline(model,X,Y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;model %s is done,score is %f&#x27;</span>%(name,dic[name]))</span><br><span class="line">order=<span class="built_in">sorted</span>(dic.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3><span id="分类调参onekey">分类调参Onekey</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">```</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 回归</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 回归OneKey</span></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">%%time</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> HuberRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lars</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LassoLars</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> PassiveAggressiveRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RANSACRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor,GradientBoostingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># prepare a list of ml models</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_models</span>(<span class="params">models=<span class="built_in">dict</span>(<span class="params"></span>)</span>):</span><br><span class="line">    <span class="comment"># linear models</span></span><br><span class="line">    models[<span class="string">&#x27;rfr&#x27;</span>]=RandomForestRegressor()</span><br><span class="line">    models[<span class="string">&#x27;gbr&#x27;</span>]=GradientBoostingRegressor()</span><br><span class="line">    models[<span class="string">&#x27;lr&#x27;</span>] = LinearRegression()</span><br><span class="line">    models[<span class="string">&#x27;lasso&#x27;</span>] = Lasso()</span><br><span class="line">    models[<span class="string">&#x27;ridge&#x27;</span>] = Ridge()</span><br><span class="line">    models[<span class="string">&#x27;en&#x27;</span>] = ElasticNet()</span><br><span class="line">    models[<span class="string">&#x27;huber&#x27;</span>] = HuberRegressor()</span><br><span class="line">    models[<span class="string">&#x27;lars&#x27;</span>] = Lars()</span><br><span class="line">    models[<span class="string">&#x27;llars&#x27;</span>] = LassoLars()</span><br><span class="line">    models[<span class="string">&#x27;pa&#x27;</span>] = PassiveAggressiveRegressor(max_iter=<span class="number">1000</span>, tol=<span class="number">1e-3</span>)</span><br><span class="line">    models[<span class="string">&#x27;ranscac&#x27;</span>] = RANSACRegressor()</span><br><span class="line">    models[<span class="string">&#x27;sgd&#x27;</span>] = SGDRegressor(max_iter=<span class="number">1000</span>, tol=<span class="number">1e-3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Defined %d models&#x27;</span> % <span class="built_in">len</span>(models))</span><br><span class="line">    <span class="keyword">return</span> models</span><br><span class="line"> </span><br><span class="line"><span class="comment"># create a feature preparation pipeline for a model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_pipeline</span>(<span class="params">model</span>):</span><br><span class="line">    steps = <span class="built_in">list</span>()</span><br><span class="line">    <span class="comment"># standardization</span></span><br><span class="line">    steps.append((<span class="string">&#x27;standardize&#x27;</span>, StandardScaler()))</span><br><span class="line">    <span class="comment"># normalization</span></span><br><span class="line">    steps.append((<span class="string">&#x27;normalize&#x27;</span>, MinMaxScaler()))</span><br><span class="line">    <span class="comment"># the model</span></span><br><span class="line">    steps.append((<span class="string">&#x27;model&#x27;</span>, model))</span><br><span class="line">    <span class="comment"># create pipeline</span></span><br><span class="line">    pipeline = Pipeline(steps)</span><br><span class="line">    <span class="keyword">return</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_validation</span>(<span class="params">pipeline,X,Y</span>):</span><br><span class="line">    <span class="keyword">return</span> cross_val_score(pipeline,X,Y,cv=<span class="number">10</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validation</span>(<span class="params">pipeline,Xtrain,Ytrain,Xtest,Ytest</span>):</span><br><span class="line">    pipeline.fit(Xtrain,Ytrain)</span><br><span class="line">    <span class="keyword">return</span> pipeline.score(Xtest,Ytest)</span><br><span class="line"></span><br><span class="line">dic = &#123;&#125;</span><br><span class="line">models = get_models()</span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    pipeline = make_pipeline(model)</span><br><span class="line">    <span class="comment"># dic[name] = cross_validation(pipeline,Xtrain,Ytrain)</span></span><br><span class="line">    dic[name] = validation(pipeline,Xtrain,Ytrain,Xtest,Ytest)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;model %s is done,score is %f&#x27;</span>%(name,dic[name]))</span><br><span class="line">order=<span class="built_in">sorted</span>(dic.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plot_data = pd.DataFrame(data=order)</span><br><span class="line">plot_data.columns = [<span class="string">&#x27;algo&#x27;</span>,<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">plot_data.set_index(<span class="string">&#x27;algo&#x27;</span>).plot.bar(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">360</span>)</span><br><span class="line"><span class="string">f&#x27;%s is the best,score is %f&#x27;</span>%(order[<span class="number">0</span>][<span class="number">0</span>],order[<span class="number">0</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create a feature preparation pipeline for a model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_pipeline</span>(<span class="params">model,Xtrain,Ytrain,Xtest,Ytest</span>):</span><br><span class="line">	steps = <span class="built_in">list</span>()</span><br><span class="line">	<span class="comment"># standardization</span></span><br><span class="line">	steps.append((<span class="string">&#x27;standardize&#x27;</span>, StandardScaler()))</span><br><span class="line">	<span class="comment"># normalization</span></span><br><span class="line">	steps.append((<span class="string">&#x27;normalize&#x27;</span>, MinMaxScaler()))</span><br><span class="line">	<span class="comment"># the model</span></span><br><span class="line">	steps.append((<span class="string">&#x27;model&#x27;</span>, model))</span><br><span class="line">	<span class="comment"># create pipeline</span></span><br><span class="line">	pipeline = Pipeline(steps).fit(Xtrain,Ytrain)</span><br><span class="line">	<span class="keyword">return</span> pipeline.score(Xtest,Ytest)</span><br><span class="line"></span><br><span class="line">dic = &#123;&#125;</span><br><span class="line">models = get_models()</span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    dic[name] = make_pipeline(model,Xtrain,Ytrain,Xtest,Ytest)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;model %s is done,score is %f&#x27;</span>%(name,dic[name]))</span><br><span class="line">order=<span class="built_in">sorted</span>(dic.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h2><span id="模板">模板</span></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df.describe([<span class="number">0.01</span>,<span class="number">0.05</span>,<span class="number">0.1</span>,<span class="number">0.25</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.9</span>,<span class="number">0.99</span>]).T</span><br><span class="line">df.describe(include=[<span class="string">&#x27;O&#x27;</span>])</span><br><span class="line"><span class="comment"># 提取连续，离散的数据</span></span><br><span class="line">col = df.columns.tolist()</span><br><span class="line">cate = df.columns[df.dtypes == <span class="string">&quot;object&quot;</span>].tolist()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> cate:</span><br><span class="line">    col.remove(i)</span><br><span class="line"><span class="comment"># 转换</span></span><br><span class="line">df[<span class="string">&#x27;a&#x27;</span>] = df[<span class="string">&#x27;a&#x27;</span>].replace(<span class="string">&#x27;[\$,)]&#x27;</span>,<span class="string">&#x27;&#x27;</span>,regex=<span class="literal">True</span>).astype(<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 离散一般填众数，连续填均值</span></span><br><span class="line">df[<span class="string">&#x27;b&#x27;</span>]=df[<span class="string">&#x27;b&#x27;</span>].fillna(df.b.mean())</span><br><span class="line">df[<span class="string">&#x27;c&#x27;</span>]=df[<span class="string">&#x27;c&#x27;</span>].fillna(df.b.mode()[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 哑变量操作</span></span><br><span class="line">cate = df.columns[df.dtypes == <span class="string">&quot;object&quot;</span>].tolist()</span><br><span class="line">cate</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> cate:</span><br><span class="line">    df = pd.concat([df,pd.get_dummies(df[c],prefix=<span class="built_in">str</span>(c))],axis=<span class="number">1</span>)</span><br><span class="line">    df.drop(c,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 变量操作</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getTitle</span>(<span class="params">name</span>):</span><br><span class="line">    str1=name.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>]   <span class="comment">#取头衔.姓</span></span><br><span class="line">    str2=str1.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]   <span class="comment">#取头衔</span></span><br><span class="line">    <span class="comment">#strip() 移除字符串头尾指定的字符</span></span><br><span class="line">    str3=str2.strip()</span><br><span class="line">    <span class="keyword">return</span> str3</span><br><span class="line">titleDf = pd.DataFrame()</span><br><span class="line"><span class="comment">#map方法---对series里面每个数据应用自定义函数计算</span></span><br><span class="line">titleDf[<span class="string">&#x27;Title&#x27;</span>] = full[<span class="string">&#x27;Name&#x27;</span>].<span class="built_in">map</span>(getTitle)</span><br><span class="line"><span class="comment"># 根据其他列数据新建onehot</span></span><br><span class="line">df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;Date&#x27;</span>].dt.month</span><br><span class="line">familyDf = pd.DataFrame()</span><br><span class="line">familyDf[<span class="string">&#x27;FamilySize&#x27;</span>] = full[<span class="string">&#x27;Parch&#x27;</span>]+full[<span class="string">&#x27;SibSp&#x27;</span>]+<span class="number">1</span></span><br><span class="line">familyDf[<span class="string">&#x27;Family_Single&#x27;</span>] = familyDf[<span class="string">&#x27;FamilySize&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> s : <span class="number">1</span> <span class="keyword">if</span> s == <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> )</span><br><span class="line">familyDf[<span class="string">&#x27;Family_Small&#x27;</span>] = familyDf[<span class="string">&#x27;FamilySize&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> s : <span class="number">1</span> <span class="keyword">if</span> <span class="number">2</span>&lt;= s &lt;= <span class="number">4</span> <span class="keyword">else</span> <span class="number">0</span> )</span><br><span class="line">familyDf[<span class="string">&#x27;Family_Large&#x27;</span>] = familyDf[<span class="string">&#x27;FamilySize&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> s : <span class="number">1</span> <span class="keyword">if</span> <span class="number">5</span>&lt;= s <span class="keyword">else</span> <span class="number">0</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看相关性</span></span><br><span class="line">corrDf = full.corr()</span><br><span class="line">survived_rel=corrDf[<span class="string">&#x27;Survived&#x27;</span>].sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3><span id="泰坦尼克">泰坦尼克</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;train.csv&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;test.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train.head()</span><br><span class="line"></span><br><span class="line">train.info()</span><br><span class="line"></span><br><span class="line">train.describe([<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">0.25</span>,<span class="number">0.5</span>,<span class="number">0.75</span>,<span class="number">0.9</span>,<span class="number">0.99</span>]).T</span><br><span class="line"></span><br><span class="line">train.isna().<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">train.Age.fillna(train.Age.mean(),inplace=<span class="literal">True</span>)</span><br><span class="line">train[<span class="string">&#x27;Embarked&#x27;</span>].fillna(train.Embarked.mode()[<span class="number">0</span>],inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train.Cabin.value_counts()</span><br><span class="line"></span><br><span class="line">train.Cabin.fillna(<span class="string">&#x27;Unknown&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train.set_index(<span class="string">&#x27;PassengerId&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train[<span class="string">&#x27;FamilySize&#x27;</span>] = train[<span class="string">&#x27;SibSp&#x27;</span>]+train[<span class="string">&#x27;Parch&#x27;</span>]+<span class="number">1</span></span><br><span class="line">train.drop([<span class="string">&#x27;SibSp&#x27;</span>,<span class="string">&#x27;Parch&#x27;</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train.Cabin = train.Cabin.<span class="built_in">map</span>(<span class="keyword">lambda</span> x : x[<span class="number">0</span>])</span><br><span class="line">train.Cabin.value_counts()</span><br><span class="line"></span><br><span class="line">train[<span class="string">&#x27;Name&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]).value_counts()</span><br><span class="line">train[<span class="string">&#x27;Name&#x27;</span>]=train[<span class="string">&#x27;Name&#x27;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">train.drop(<span class="string">&#x27;Ticket&#x27;</span>,axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">col = train.columns[train.dtypes == <span class="string">&quot;object&quot;</span>].tolist()</span><br><span class="line">col</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> col:</span><br><span class="line">    train = pd.concat([train,pd.get_dummies(train[c],prefix=<span class="built_in">str</span>(c))],axis=<span class="number">1</span>)</span><br><span class="line">    train.drop(c,inplace=<span class="literal">True</span>,axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">corrDf = train.corr()</span><br><span class="line">survived_rel=corrDf[<span class="string">&#x27;Survived&#x27;</span>].sort_values(ascending = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">Ytrain = train[<span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line">Xtrain = train.drop(<span class="string">&#x27;Survived&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">%%time</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression,  SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># prepare a list of ml models</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_models</span>(<span class="params">models=<span class="built_in">dict</span>(<span class="params"></span>)</span>):</span><br><span class="line">    <span class="comment"># linear models</span></span><br><span class="line">    models[<span class="string">&#x27;gbc&#x27;</span>] = GradientBoostingClassifier()</span><br><span class="line">    models[<span class="string">&#x27;rfc&#x27;</span>] = RandomForestClassifier()</span><br><span class="line">    models[<span class="string">&#x27;lr&#x27;</span>] = LogisticRegression()</span><br><span class="line">    models[<span class="string">&#x27;KNN&#x27;</span>] = KNeighborsClassifier()</span><br><span class="line">    models[<span class="string">&#x27;GaussianNB&#x27;</span>] =  GaussianNB()</span><br><span class="line">    models[<span class="string">&#x27;sgd&#x27;</span>] = SGDClassifier()</span><br><span class="line">    models[<span class="string">&#x27;lsvc&#x27;</span>] =LinearSVC()</span><br><span class="line">    models[<span class="string">&#x27;svc&#x27;</span>] = SVC()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Defined %d models&#x27;</span> % <span class="built_in">len</span>(models))</span><br><span class="line">    <span class="keyword">return</span> models</span><br><span class="line"><span class="comment"># create a feature preparation pipeline for a model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_pipeline</span>(<span class="params">model,X, Y</span>):</span><br><span class="line">    steps = <span class="built_in">list</span>()</span><br><span class="line">    <span class="comment"># standardization</span></span><br><span class="line">    steps.append((<span class="string">&#x27;standardize&#x27;</span>, StandardScaler()))</span><br><span class="line">    <span class="comment"># normalization</span></span><br><span class="line">    steps.append((<span class="string">&#x27;normalize&#x27;</span>, MinMaxScaler()))</span><br><span class="line">    <span class="comment"># the model</span></span><br><span class="line">    steps.append((<span class="string">&#x27;model&#x27;</span>, model))</span><br><span class="line">    <span class="comment"># create pipeline</span></span><br><span class="line">    pipeline = Pipeline(steps)</span><br><span class="line">    <span class="keyword">return</span> cross_val_score(pipeline,X,Y,cv=<span class="number">4</span>).mean()</span><br><span class="line">dic = &#123;&#125;</span><br><span class="line">models = get_models()</span><br><span class="line"><span class="keyword">for</span> name, model <span class="keyword">in</span> models.items():</span><br><span class="line">    dic[name] = make_pipeline(model,Xtrain,Ytrain)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;model %s is done,score is %f&#x27;</span>%(name,dic[name]))</span><br><span class="line">order=<span class="built_in">sorted</span>(dic.items(),key=<span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plot_data = pd.DataFrame(data=order)</span><br><span class="line">plot_data.columns = [<span class="string">&#x27;algo&#x27;</span>,<span class="string">&#x27;score&#x27;</span>]</span><br><span class="line">plot_data.set_index(<span class="string">&#x27;algo&#x27;</span>).plot.bar(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.xticks(rotation=<span class="number">360</span>)</span><br><span class="line"><span class="string">f&#x27;%s is the best,score is %f&#x27;</span>%(order[<span class="number">0</span>][<span class="number">0</span>],order[<span class="number">0</span>][<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<h3><span id="调优">调优</span></h3><p>岭回归可以解决特征间的精确相关关系导致的最小二乘法无法使用的问题，而Lasso不行。</p>
<p>由于Lasso对正则化系数的变动过于敏感，因此我们往往让 在很小的空间中变动</p>
<h3><span id="ridge">Ridge</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">housevalue = fch()</span><br><span class="line">X = pd.DataFrame(housevalue.data) y = housevalue.target</span><br><span class="line">X.columns = [<span class="string">&quot;住户收入中位数&quot;</span>,<span class="string">&quot;房屋使用年代中位数&quot;</span>,<span class="string">&quot;平均房间数目&quot;</span></span><br><span class="line">           ,<span class="string">&quot;平均卧室数目&quot;</span>,<span class="string">&quot;街区人口&quot;</span>,<span class="string">&quot;平均入住率&quot;</span>,<span class="string">&quot;街区的纬度&quot;</span>,<span class="string">&quot;街区的经度&quot;</span>]</span><br><span class="line">Ridge_ = RidgeCV(alphas=np.arange(<span class="number">1</span>,<span class="number">1001</span>,<span class="number">100</span>)</span><br><span class="line">                <span class="comment">#,scoring=&quot;neg_mean_squared_error&quot;</span></span><br><span class="line">                 ,store_cv_values=<span class="literal">True</span></span><br><span class="line">                <span class="comment">#,cv=5</span></span><br><span class="line">               ).fit(X, y)</span><br><span class="line"></span><br><span class="line">Ridge_.score(X,y) <span class="comment">#调用所有交叉验证的结果</span></span><br><span class="line">Ridge_.cv_values_.shape</span><br><span class="line"><span class="comment">#进行平均后可以查看每个正则化系数取值下的交叉验证结果</span></span><br><span class="line">Ridge_.cv_values_.mean(axis=<span class="number">0</span>) <span class="comment">#查看被选择出来的最佳正则化系数</span></span><br><span class="line">Ridge_.alpha_</span><br></pre></td></tr></table></figure>

<h3><span id="lasso">Lasso</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LassoCV</span><br><span class="line"><span class="comment">#自己建立Lasso进行alpha选择的范围</span></span><br><span class="line">alpharange = np.logspace(-<span class="number">10</span>, -<span class="number">2</span>, <span class="number">200</span>,base=<span class="number">10</span>) <span class="comment">#其实是形成10为底的指数函数</span></span><br><span class="line"><span class="comment">#10**(-10)到10**(-2)次方</span></span><br><span class="line">alpharange.shape</span><br><span class="line">Xtrain.head()</span><br><span class="line">lasso_ = LassoCV(alphas=alpharange <span class="comment">#自行输入的alpha的取值范围</span></span><br><span class="line">               ,cv=<span class="number">5</span> <span class="comment">#交叉验证的折数</span></span><br><span class="line">               ).fit(Xtrain, Ytrain) <span class="comment">#查看被选择出来的最佳正则化系数</span></span><br><span class="line">lasso_.alpha_</span><br><span class="line"><span class="comment">#调用所有交叉验证的结果</span></span><br><span class="line">lasso_.mse_path_</span><br><span class="line">lasso_.mse_path_.shape <span class="comment">#返回每个alpha下的五折交叉验证结果</span></span><br><span class="line">lasso_.mse_path_.mean(axis=<span class="number">1</span>) <span class="comment">#有注意到在岭回归中我们的轴向是axis=0吗？</span></span><br><span class="line"><span class="comment">#在岭回归当中，我们是留一验证，因此我们的交叉验证结果返回的是，每一个样本在每个alpha下的交叉验证结果</span></span><br><span class="line"><span class="comment">#因此我们要求每个alpha下的交叉验证均值，就是axis=0，跨行求均值</span></span><br><span class="line"><span class="comment">#而在这里，我们返回的是，每一个alpha取值下，每一折交叉验证的结果</span></span><br><span class="line"><span class="comment">#因此我们要求每个alpha下的交叉验证均值，就是axis=1，跨列求均值</span></span><br><span class="line"><span class="comment">#最佳正则化系数下获得的模型的系数结果</span></span><br><span class="line">lasso_.coef_</span><br><span class="line">lasso_.score(Xtest,Ytest) <span class="comment">#与线性回归相比如何？</span></span><br><span class="line">reg = LinearRegression().fit(Xtrain,Ytrain)</span><br><span class="line">reg.score(Xtest,Ytest) <span class="comment">#使用lassoCV自带的正则化路径长度和路径中的alpha个数来自动建立alpha选择的范围</span></span><br><span class="line">ls_ = LassoCV(eps=<span class="number">0.00001</span></span><br><span class="line">             ,n_alphas=<span class="number">300</span></span><br><span class="line">             ,cv=<span class="number">5</span></span><br><span class="line">               ).fit(Xtrain, Ytrain)</span><br><span class="line">ls_.alpha_</span><br><span class="line">ls_.alphas_ <span class="comment">#查看所有自动生成的alpha取值</span></span><br><span class="line">ls_.alphas_.shape</span><br><span class="line">ls_.score(Xtest,Ytest)</span><br><span class="line">ls_.coef_</span><br></pre></td></tr></table></figure>



<h3><span id="多步长时间序列">多步长时间序列</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>) <span class="comment"># 展示所有列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;data.csv&#x27;</span>)</span><br><span class="line">df[<span class="string">&#x27;Date&#x27;</span>] = pd.to_datetime(df[<span class="string">&#x27;Date&#x27;</span>])</span><br><span class="line">df[<span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;Date&#x27;</span>].dt.month</span><br><span class="line">df[<span class="string">&#x27;dayofweek&#x27;</span>] = df[<span class="string">&#x27;Date&#x27;</span>].dt.dayofweek</span><br><span class="line">df[[<span class="string">&#x27;holiday&#x27;</span>,<span class="string">&#x27;month&#x27;</span>,<span class="string">&#x27;dayofweek&#x27;</span>]] = df[[<span class="string">&#x27;holiday&#x27;</span>,<span class="string">&#x27;month&#x27;</span>,<span class="string">&#x27;dayofweek&#x27;</span>]].astype(<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">df = pd.get_dummies(df)</span><br><span class="line">df.drop(<span class="string">&#x27;Season&#x27;</span>,inplace=<span class="literal">True</span>,axis=<span class="number">1</span>)</span><br><span class="line">df.info()</span><br><span class="line">df.set_index(<span class="string">&#x27;Date&#x27;</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">data = df.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 相关函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_lag</span>(<span class="params">df,l_beg = <span class="number">1</span>,l_end = <span class="number">32</span></span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(l_beg,l_end):</span><br><span class="line">        df[<span class="string">&#x27;lag_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i)] = df.DailyElectricity.shift(i)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_data</span>(<span class="params">n_days,df,indx</span>):</span><br><span class="line">    Y_val = df.iloc[-n_days:,indx].copy()</span><br><span class="line">    df.iloc[-n_days:,indx]=<span class="number">0</span></span><br><span class="line">    make_lag(df)</span><br><span class="line">    X_val = df.iloc[-n_days:].drop(<span class="string">&#x27;DailyElectricity&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">    df.dropna(inplace=<span class="literal">True</span>)</span><br><span class="line">    X = df[:-n_days].drop(<span class="string">&#x27;DailyElectricity&#x27;</span>,axis=<span class="number">1</span>)</span><br><span class="line">    Y = df[:-n_days][<span class="string">&#x27;DailyElectricity&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> X,Y,X_val,Y_val</span><br><span class="line">  </span><br><span class="line">df = data.copy()</span><br><span class="line">X,Y,X_val,Y_val = split_data(<span class="number">365</span>,df,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostRegressor,RandomForestRegressor,GradientBoostingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression,Lasso,LassoLars,SGDRegressor,Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_models</span>(<span class="params">models=&#123;&#125;</span>):</span><br><span class="line">    models[<span class="string">&#x27;AdaBoostRegressor&#x27;</span>]=AdaBoostRegressor()</span><br><span class="line">    models[<span class="string">&#x27;RandomForestRegressor&#x27;</span>]=RandomForestRegressor()</span><br><span class="line">    models[<span class="string">&#x27;GradientBoostingRegressor&#x27;</span>]=GradientBoostingRegressor()</span><br><span class="line">    models[<span class="string">&#x27;LinearRegression&#x27;</span>]=LinearRegression()</span><br><span class="line">    models[<span class="string">&#x27;Lasso&#x27;</span>]=Lasso()</span><br><span class="line">    models[<span class="string">&#x27;LassoLars&#x27;</span>]=LassoLars()</span><br><span class="line">    models[<span class="string">&#x27;SGDRegressor&#x27;</span>]=SGDRegressor()</span><br><span class="line">    models[<span class="string">&#x27;Ridge&#x27;</span>]=Ridge()</span><br><span class="line">    <span class="keyword">return</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_pipe</span>(<span class="params">model</span>):</span><br><span class="line">    steps = [(<span class="string">&#x27;s&#x27;</span>,StandardScaler()),(<span class="string">&#x27;m&#x27;</span>,model)]</span><br><span class="line">    <span class="keyword">return</span> Pipeline(steps)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">val</span>(<span class="params">model,x,y,cv=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> cross_val_score(model,X,Y,cv=cv).mean()</span><br><span class="line"></span><br><span class="line">s = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> n,m <span class="keyword">in</span> get_models().items():</span><br><span class="line">    p = make_pipe(m)</span><br><span class="line">    s[n]=val(m,X,Y)</span><br><span class="line">order = <span class="built_in">sorted</span>(s.items(),key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>],reverse=<span class="literal">True</span>)</span><br><span class="line">order</span><br><span class="line"></span><br><span class="line">pipe = make_pipe(GradientBoostingRegressor())</span><br><span class="line">best_model = pipe.fit(X,Y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pred_date</span>(<span class="params">X_val</span>):</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X_val.shape[<span class="number">0</span>]):</span><br><span class="line">        pred = best_model.predict(np.array(X_val.iloc[i]).reshape(<span class="number">1</span>,-<span class="number">1</span>))</span><br><span class="line">        res.append(pred)</span><br><span class="line">        <span class="keyword">if</span> i+<span class="number">1</span> &lt; X_val.shape[<span class="number">0</span>]:</span><br><span class="line">            X_val.iloc[i+<span class="number">1</span>,-<span class="number">30</span>:] = X_val.iloc[i,-<span class="number">31</span>:-<span class="number">1</span>]</span><br><span class="line">            X_val.iloc[i+<span class="number">1</span>,-<span class="number">31</span>]=pred</span><br><span class="line">    <span class="keyword">return</span> X_val,res</span><br><span class="line">  </span><br><span class="line">X_val,res = pred_date(X_val) </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score,mean_squared_error</span><br><span class="line">mean_squared_error(Y_val,res)</span><br><span class="line">r2_score(Y_val,res)</span><br></pre></td></tr></table></figure>



<h2><span id="踩坑">踩坑</span></h2><ul>
<li>关于数据预处理</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	预处理的时候不能</span></span><br><span class="line"><span class="string">		scaler.fit_trainsform(Xtest)</span></span><br><span class="line"><span class="string">		或者</span></span><br><span class="line"><span class="string">		scaler.fit(Xtest)</span></span><br><span class="line"><span class="string">		scaler.transform(Xtest)</span></span><br><span class="line"><span class="string">	因为会导致数据泄露</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">scaler = StandardScaler() <span class="comment">#实例化</span></span><br><span class="line">scaler.fit(Xtrain)</span><br><span class="line">X_train =scaler.transform(Xtrain)</span><br><span class="line">X_test =scaler.transform(Xtest)</span><br><span class="line">norm = MinMaxScaler()</span><br><span class="line">norm.fit(Xtrain)</span><br><span class="line">X_train = norm.transform(Xtrain)</span><br><span class="line">X_test = norm.transform(Xtest)</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler() <span class="comment">#实例化</span></span><br><span class="line">X_train =scaler.fit_transform(Xtrain)</span><br><span class="line">X_test =scaler.transform(Xtest)</span><br><span class="line">norm = MinMaxScaler()</span><br><span class="line">norm.fit(Xtrain)</span><br><span class="line">X_train = norm.fit_transform(Xtrain)</span><br><span class="line">X_test = norm.transform(Xtest)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>关于预测</p>
<p>预测的时候要将整个数据拿去fit,然后再去predict</p>
</li>
</ul>
<h2><span id="trick">Trick</span></h2><ul>
<li><p>get_dummies的时候最好先把 预测集和测试集合并再分开X[:x.shape[0]]</p>
</li>
<li><p>factorized转换回去</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">orig_col = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">labels, uniques = pd.factorize(orig_col)</span><br><span class="line"></span><br><span class="line"><span class="comment"># To get original list back</span></span><br><span class="line">uniques[labels]</span><br><span class="line"><span class="comment"># array([&#x27;b&#x27;, &#x27;b&#x27;, &#x27;a&#x27;, &#x27;c&#x27;, &#x27;b&#x27;], dtype=object)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>pandas改变行序列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">col=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>]</span><br><span class="line">df[col]</span><br></pre></td></tr></table></figure>
</li>
<li><p>按月份统计 </p>
<ul>
<li>A 星期</li>
<li>B 月份</li>
</ul>
<p><code>df.groupby(df[&#39;date&#39;].dt.strftime(&#39;%B&#39;))[&#39;price&#39;].mean()</code></p>
<p><code>df[&#39;month&#39;] = df[&#39;Date&#39;].dt.month</code></p>
</li>
<li><p>排序后按自定义顺序显示</p>
<p><code>cat = [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]</code></p>
<p><code>df.groupby(&#39;f&#39;).reindex(cat)</code></p>
</li>
<li><p>透视</p>
<p><code>df = df.groupby(&#39;name&#39;,&#39;year&#39;)[&#39;gdp&#39;].sum().reindex()</code></p>
<p><code>df.pivot(index=&#39;name&#39;,columns=&#39;year&#39;,values=&#39;gdp&#39;)</code></p>
<p>![透视前](&#x2F;Users&#x2F;disda&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220310161405868.png)</p>
<p>![透视后](&#x2F;Users&#x2F;disda&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220310161422071.png)</p>
<p><strong>定类数据</strong></p>
<p>字符型，此类数据只代表“类别”，类别与类别之间没有必然的相关关系，提供的信息量也最少。例如（颜色：红色，黄色，蓝色，绿色）</p>
<p>处理方式：ｏｎｅ－ｈｏｔ编码</p>
<p><strong>定序数据</strong></p>
<p>字符型，此类数据代表“类别”的同时类别与类别之间可以比较，有顺序。例如（品质：优，良，中，差）</p>
<p>处理方式：对字符型数值赋值</p>
<p><strong>定距数据</strong></p>
<p>数值型，可加减。用于统计计数。例如（卧室数量）</p>
<p>处理方式：极差缩放，标准化</p>
<p><strong>定比数据</strong></p>
<p>数值型，可加减乘除，有绝对“０”值的概念。例如（工资，￥１００是￥５０的２倍）</p>
<p>处理方式：极差缩放，数值归一化，标准化</p>
</li>
</ul>
</div></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: 'd154fff64901622afbb6',
  clientSecret: '5b3f1d58c331b54703e4477e1f8fa1e42e9c1082',
  repo: 'Disda-coding.github.io',
  owner: 'Disda-coding',
  admin: ['Disda-coding'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div><div class="pure-u-1 pure-u-md-4-4"><div id="footer">Copyright © 2025 <a href="/." rel="nofollow">Disda.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> </a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Disda.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/2.0.4/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/2.1.4/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/2.1.4/toastr.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>